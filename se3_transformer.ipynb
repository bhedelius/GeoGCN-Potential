{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "se3-transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulxwtkGl_5aK"
      },
      "source": [
        "# Install libraries\r\n",
        "!pip install --pre dgl-cu101\r\n",
        "\r\n",
        "# Import libraries\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import dgl\r\n",
        "import dgl.function as fn\r\n",
        "from dgl import DGLGraph\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from scipy.special import sph_harm as sph_harm_func"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG91AePzwoUk"
      },
      "source": [
        "from numpy import sqrt\r\n",
        "from scipy.special import factorial\r\n",
        "\r\n",
        "\r\n",
        "def clebsch_gordan(j1,j2,m1,m2,J,M=None):\r\n",
        "  ''' Using equation from Wikipedia:\r\n",
        "  https://en.wikipedia.org/wiki/Table_of_Clebschâ€“Gordan_coefficients.\r\n",
        "\r\n",
        "  The equation isn't numerically stable and not fast (speed isn't too important)\r\n",
        "  TODO: Possibly find more stable implementation'''\r\n",
        "  if M is None:\r\n",
        "    M=m1+m2\r\n",
        "  if M<0:\r\n",
        "    return (-1)**(J-j1-j2)*clebsch_gordan(j1,j2,-m1,-m2,J,-M)\r\n",
        "  if j1<j2:\r\n",
        "    return (-1)**(J-j1-j2)*clebsch_gordan(j2,j1,m2,m1,J,M)\r\n",
        "  if not M==m1+m2:\r\n",
        "    return 0\r\n",
        "  A = sqrt((2*J+1)*factorial(J+j1-j2)*factorial(J-j1+j2)*factorial(j1+j2-J)/factorial(j1+j2+J+1))\r\n",
        "  B = sqrt(factorial(J+M)*factorial(J-M)*factorial(j1-m1)*factorial(j1+m1)*factorial(j2-m2)*factorial(j2+m2))\r\n",
        "  k_max = min([j1+j2-J,j1-m1,j2+m2])\r\n",
        "  k_min = max([0,-(J-j2+m1),-(J-j1-m2)])\r\n",
        "  C = 0\r\n",
        "  for k in range(int(k_min), int(k_max)+1):\r\n",
        "    C += (-1)**k/(factorial(k)*factorial(j1+j2-J-k)*factorial(j1-m1-k)*factorial(j2+m2-k)*factorial(J-j2+m1+k)*factorial(J-j1-m2+k))\r\n",
        "  return A*B*C\r\n",
        "\r\n",
        "def clebsch_gordan_mat(j1,j2,J,m):\r\n",
        "  mat = torch.zeros((int(2*j1+1),int(2*j2+1)))\r\n",
        "  for i, m1 in enumerate(torch.arange(-j1, j1+1)):\r\n",
        "    for j, m2 in enumerate(torch.arange(-j2, j2+1)):\r\n",
        "      mat[i,j] = clebsch_gordan(j1,j2,m1,m2,J,m)\r\n",
        "  return mat\r\n",
        "\r\n",
        "def clebsch_gordan_mats(j1,j2,J):\r\n",
        "  mats = torch.zeros(2*J+1,2*j1+1,2*j2+1)\r\n",
        "  for x, m in enumerate(torch.arange(-J, J+1)):\r\n",
        "    for y, m1 in enumerate(torch.arange(-j1, j1+1)):\r\n",
        "      for z, m2 in enumerate(torch.arange(-j2, j2+1)):\r\n",
        "        mats[x,y,z] = clebsch_gordan(j1,j2,m1,m2,J)\r\n",
        "  return mats\r\n",
        "\r\n",
        "clebsch_gordan(1/2,1/2,-1/2,1/2,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDfUPE4SKm90"
      },
      "source": [
        "class PointCloud:\r\n",
        "  '''Represents a point cloud in R^3. This class calculates and stores relevant\r\n",
        "  information such as the vectors, distances, directions, and spherical\r\n",
        "  harmonics of the vectors.'''\r\n",
        "  # new_g, new_ntypes, new_etypes, new_nframes, new_eframes\r\n",
        "  def __init__(self, pos, cutoff=8.0):\r\n",
        "    edges = self._find_edges_(pos, cutoff)\r\n",
        "    self.graph = dgl.graph(edges)\r\n",
        "    self.graph.ndata['pos'] = pos\r\n",
        "    self._calc_edge_info_()\r\n",
        "    self.sph_harm = dict()\r\n",
        "    self.wj = dict()\r\n",
        "\r\n",
        "  def _find_edges_(self, pos, cutoff):\r\n",
        "    # Use positions to create graph. Need to improve! Currently O(n^2)\r\n",
        "    self.vec_mat = pos[:,None,:]-pos[None,:,:]\r\n",
        "    self.dist_mat = torch.sqrt(torch.sum((self.vec_mat)**2,axis=-1))\r\n",
        "    u = []\r\n",
        "    v = []\r\n",
        "    for j in range(len(pos)):\r\n",
        "      for i in range(j):\r\n",
        "        if self.dist_mat[i,j] < cutoff:\r\n",
        "          u.append(i)\r\n",
        "          v.append(j)\r\n",
        "    u, v = torch.tensor(u+v), torch.tensor(v+u)\r\n",
        "    return (u,v)\r\n",
        "\r\n",
        "  def _calc_edge_info_(self):\r\n",
        "    # Calculate and store position and angle information\r\n",
        "    u,v = self.graph.edges()[0], self.graph.edges()[1]\r\n",
        "    vec = self.vec_mat[u,v]\r\n",
        "    self.graph.edata['vec'] = vec\r\n",
        "    dist = self.dist_mat[u,v]\r\n",
        "    self.graph.edata['dist'] = dist\r\n",
        "    dir = vec/dist[:,None]\r\n",
        "    self.graph.edata['dir'] = dir\r\n",
        "    self.graph.edata['theta'] = torch.atan2(dir[:,1], dir[:,0])\r\n",
        "    self.graph.edata['phi'] = torch.arccos(dir[:,2])\r\n",
        "\r\n",
        "  def get_sph_harm(self, J):\r\n",
        "    # Returns spherical harmonic of order J.\r\n",
        "    if not J in self.sph_harm.keys():\r\n",
        "      m = torch.arange(-J,J+1)\r\n",
        "      theta = self.graph.edata['theta']\r\n",
        "      phi = self.graph.edata['phi']\r\n",
        "      self.sph_harm[J] = torch.real(sph_harm_func(m[None,:], J, theta[:,None], phi[:,None])).double()\r\n",
        "    return self.sph_harm[J]\r\n",
        "    \r\n",
        "  def get_wj(self, l, k):\r\n",
        "    # This needs to be improved\r\n",
        "    if not (l,k) in self.wj.keys():\r\n",
        "      wj = torch.zeros(k+l-abs(k-l)+1, self.graph.number_of_edges(), 2*l+1, 2*k+1)\r\n",
        "      for i, J in enumerate(range(abs(k-l), k+l+1)):\r\n",
        "        sh = self.get_sph_harm(J)\r\n",
        "        cg = clebsch_gordan_mats(l,k,J).double()\r\n",
        "        wj[i] = torch.einsum(\"em,mlk->elk\",sh, cg)\r\n",
        "      self.wj[(l,k)] = wj.transpose(0,1).clone()\r\n",
        "    return self.wj[(l,k)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-1fP9JqcTkZ"
      },
      "source": [
        "class WLayer(nn.Module):\r\n",
        "  def __init__(self, k, l, channels=1):\r\n",
        "    super(WLayer, self).__init__()\r\n",
        "    self.k = k\r\n",
        "    self.l = l\r\n",
        "    self.channels = channels\r\n",
        "\r\n",
        "    r_size = (channels)*(k+l-abs(k-l)+1)*(2*l+1)*(2*k+1)\r\n",
        "\r\n",
        "    self.radial = nn.Sequential(nn.Linear(1,5), nn.ReLU(),\r\n",
        "                                nn.Linear(5,r_size))\r\n",
        "\r\n",
        "  def forward(self, pc):\r\n",
        "    wj = pc.get_wj(self.l, self.k)\r\n",
        "    R = self.radial(pc.graph.edata['dist'][:,None])\r\n",
        "    R = R.reshape((-1,\r\n",
        "                   self.channels,\r\n",
        "                   self.k+self.l-abs(self.k-self.l)+1,\r\n",
        "                   2*self.l+1,\r\n",
        "                   2*self.k+1))\r\n",
        "    w = torch.einsum('ecjlk,ejlk->eclk',R,wj)\r\n",
        "    return w\r\n",
        "\r\n",
        "class TFNLayer(nn.Module):\r\n",
        "  def __init__(self, k, l, channels=1):\r\n",
        "    super(TFNLayer, self).__init__()\r\n",
        "    self.k = k\r\n",
        "    self.l = l\r\n",
        "    self.channels = channels\r\n",
        "    self.wlayer = WLayer(k, l, channels)\r\n",
        "    #self.self_int = nn.linear\r\n",
        "\r\n",
        "  def forward(self, pc, feat):\r\n",
        "    with pc.graph.local_scope():\r\n",
        "      pc.graph.ndata['feat'] = feat\r\n",
        "      pc.graph.edata['w'] = self.wlayer(pc)\r\n",
        "      pc.graph.update_all(self.message_func, self.reduce_func)\r\n",
        "      return pc.graph.ndata['f']\r\n",
        "\r\n",
        "  def message_func(self, edges):\r\n",
        "    print(edges.data['w'].size(), edges.src['feat'].size())\r\n",
        "    return {'m': torch.einsum('eclk,eck->ecl',edges.data['w'],edges.src['feat'])}\r\n",
        "\r\n",
        "  def reduce_func(self,nodes):\r\n",
        "     return {'f': torch.sum(nodes.mailbox['m'], dim=1)}\r\n",
        "\r\n",
        "class TransLayer(nn.Module):\r\n",
        "  def __init__(self, k, l, channels=1):\r\n",
        "    super(TransLayer, self).__init__()\r\n",
        "    self.k = k\r\n",
        "    self.l = l\r\n",
        "    self.channels = channels\r\n",
        "\r\n",
        "    self.wklayer = WLayer(k, l, channels)\r\n",
        "    self.wvlayer = WLayer(k, l, channels)\r\n",
        "\r\n",
        "  def forward(self, pc, feat):\r\n",
        "    with pc.graph.local_scope():\r\n",
        "      pc.graph.ndata['feat'] = feat\r\n",
        "      pc.graph.edata['wk'] = self.wklayer(pc)\r\n",
        "      pc.graph.edata['wv'] = self.wvlayer(pc)\r\n",
        "      pc.graph.ndata['q'] = torch.sum(feat,-1)\r\n",
        "      pc.graph.update_all(self.attn_message, self.attn_reduce)\r\n",
        "      pc.graph.update_all(self.message_func, self.reduce_func)\r\n",
        "      return pc.graph.ndata['f']\r\n",
        "\r\n",
        "  def attn_message(self, edges):\r\n",
        "    q = edges.dst['q']\r\n",
        "    wk = edges.data['wk']\r\n",
        "    feat = edges.src['feat']\r\n",
        "    k = torch.sum(torch.einsum('eclk,eck->ecl',wk,feat),-1)\r\n",
        "    exp = torch.exp(\r\n",
        "      torch.einsum('ec,ec->ec',q,k))\r\n",
        "    edges.data['exp'] = exp\r\n",
        "    return {'exp': exp}\r\n",
        "\r\n",
        "  def attn_reduce(self, nodes):\r\n",
        "    # does sum over j'\r\n",
        "    return {'s': torch.sum(nodes.mailbox['exp'], dim=1)}\r\n",
        "\r\n",
        "  def message_func(self, edges):\r\n",
        "    attn = edges.data['exp']/edges.dst['s']\r\n",
        "    wv = edges.data['wv']\r\n",
        "    feat = edges.src['feat']\r\n",
        "\r\n",
        "    c = torch.einsum('ec,eclk,eck->ecl',attn,wv,feat)\r\n",
        "    si = edges.dst['feat']\r\n",
        "    return {'c': c+si}\r\n",
        "\r\n",
        "  def reduce_func(self,nodes):\r\n",
        "     return {'f': torch.sum(nodes.mailbox['c'], dim=1)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKd3TCy_54Q3"
      },
      "source": [
        "# Create a test graph\r\n",
        "num_pts = 10\r\n",
        "pos = torch.rand(num_pts,3)\r\n",
        "pc = PointCloud(pos)\r\n",
        "\r\n",
        "feat = torch.rand(num_pts,2,1)\r\n",
        "\r\n",
        "# TFN layer\r\n",
        "layer1 = TFNLayer(0,1,channels=2)\r\n",
        "layer1(pc, feat)\r\n",
        "\r\n",
        "# Transformer layer\r\n",
        "layer = TransLayer(0,1,channels=2)\r\n",
        "layer(pc, feat).size()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
